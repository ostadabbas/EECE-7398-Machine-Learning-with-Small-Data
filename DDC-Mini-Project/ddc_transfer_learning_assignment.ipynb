{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adaptation with Deep Domain Confusion (DDC) for Transfer Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you will implement the key components of the paper \"Deep Domain Confusion: Maximizing for Domain Invariance\" by Tzeng et al. This approach addresses the problem of domain adaptation in deep neural networks by introducing:\n",
    "\n",
    "1. An adaptation layer within a standard CNN architecture\n",
    "2. A domain confusion loss to learn domain-invariant features\n",
    "3. A method to simultaneously optimize for classification accuracy and domain invariance\n",
    "\n",
    "Throughout this assignment, you will gain hands-on experience with:\n",
    "- Understanding domain adaptation in the context of deep learning\n",
    "- Implementing Maximum Mean Discrepancy (MMD) as a metric for domain similarity\n",
    "- Modifying standard CNN architectures for transfer learning\n",
    "- Training models with multiple objective functions\n",
    "- Evaluating domain adaptation performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before proceeding, make sure you have read:\n",
    "- The original paper: \"Deep Domain Confusion: Maximizing for Domain Invariance\"\n",
    "- This notebook assumes you are familiar with PyTorch and basic deep learning concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Office-31 Dataset\n",
    "\n",
    "The Office-31 dataset is a benchmark dataset for visual domain adaptation. It contains 31 object categories in three distinct domains:\n",
    "- **Amazon (A)**: Images from amazon.com\n",
    "- **Webcam (W)**: Low-resolution images taken by a webcam\n",
    "- **DSLR (D)**: High-resolution images taken by a DSLR camera\n",
    "\n",
    "Let's implement a dataloader for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the Office31Dataset class\n",
    "class Office31Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the Office-31 dataset\n",
    "    \n",
    "    Args:\n",
    "        root_dir (string): Directory with all the images\n",
    "        domain (string): Which domain to use ('amazon', 'webcam', or 'dslr')\n",
    "        transform (callable, optional): Optional transform to be applied on a sample\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, domain, transform=None):\n",
    "        # Your code here\n",
    "        self.root_dir = root_dir\n",
    "        self.domain = domain\n",
    "        self.transform = transform\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Your code here\n",
    "        # return len(self.root_dir)\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Your code here\n",
    "        # return self.root_dir[idx], self.domain, self.transform\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define image transformations for data preprocessing\n",
    "def get_data_transforms():\n",
    "    \"\"\"\n",
    "    Define transforms for training and testing\n",
    "    \"\"\"\n",
    "    # Your code here - make sure to normalize according to ImageNet statistics \n",
    "    # since we'll be using a pretrained model\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data loaders for source and target domains\n",
    "def get_office31_dataloaders(source_domain, target_domain, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create data loaders for the source and target domains\n",
    "    \n",
    "    Args:\n",
    "        source_domain (string): Source domain name\n",
    "        target_domain (string): Target domain name\n",
    "        batch_size (int): Batch size\n",
    "        \n",
    "    Returns:\n",
    "        source_loader: DataLoader for the source domain\n",
    "        target_loader: DataLoader for the target domain\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing the Maximum Mean Discrepancy (MMD) Loss\n",
    "\n",
    "The key to the DDC approach is the use of Maximum Mean Discrepancy (MMD) as a metric to measure the distance between the source and target feature distributions. Let's implement the MMD loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the MMD (Maximum Mean Discrepancy) loss\n",
    "def mmd_loss(source_features, target_features, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    \"\"\"\n",
    "    Calculate the MMD (Maximum Mean Discrepancy) between source and target features\n",
    "    \n",
    "    Args:\n",
    "        source_features (torch.Tensor): Features from source domain (batch_size, feature_dim)\n",
    "        target_features (torch.Tensor): Features from target domain (batch_size, feature_dim)\n",
    "        kernel_mul (float): Kernel multiplier for RBF kernel\n",
    "        kernel_num (int): Number of kernels\n",
    "        fix_sigma (float): Fixed sigma value for the RBF kernel\n",
    "        \n",
    "    Returns:\n",
    "        mmd_value (torch.Tensor): MMD loss value\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Hint 1: You need to compute the mean embeddings of source and target features\n",
    "    # Hint 2: Use a Gaussian kernel with multiple bandwidths (sigma values)\n",
    "    # Hint 3: The formula is: MMD(X, Y) = ||E[φ(X)] - E[φ(Y)]||^2\n",
    "    # source_mean = torch.mean(source_features, dim=0)\n",
    "    # target_mean = torch.mean(target_features, dim=0)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Deep Domain Confusion (DDC) Network\n",
    "\n",
    "Now, let's implement the DDC network by modifying a pre-trained AlexNet model. We'll add an adaptation layer and use both classification and domain confusion losses for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the DDC network architecture\n",
    "class DDCNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Domain Confusion Network based on AlexNet\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of classes in the dataset\n",
    "        adaptation_layer_dim (int): Dimension of the adaptation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=31, adaptation_layer_dim=256):\n",
    "        super(DDCNet, self).__init__()\n",
    "        \n",
    "        # Load a pre-trained AlexNet model\n",
    "        self.alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "        \n",
    "        # Extract feature extraction layers (everything before the final classifier)\n",
    "        self.features = self.alexnet.features\n",
    "        \n",
    "        # Create adaptation layer (typically after fc7)\n",
    "        # TODO: Add the adaptation layer as described in the paper\n",
    "        # self.adaptation_layer = nn.Linear(256, adaptation_layer_dim)\n",
    "        \n",
    "        # Create classifier layers\n",
    "        # TODO: Modify the classifier to output num_classes\n",
    "        # self.classifier = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Initialize weights of the new layers\n",
    "        # TODO: Initialize the weights of the adaptation layer and new classifier layers\n",
    "        # self.adaptation_layer.weight.data.normal_(0, 0.01)\n",
    "        # self.adaptation_layer.bias.data.zero_()\n",
    "        # self.classifier.weight.data.normal_(0, 0.01)\n",
    "        # self.classifier.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, source_data, target_data=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            source_data (torch.Tensor): Source domain data\n",
    "            target_data (torch.Tensor, optional): Target domain data\n",
    "            \n",
    "        Returns:\n",
    "            source_preds: Class predictions for source data\n",
    "            (source_features, target_features): Features for domain confusion loss (if target_data is provided)\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass\n",
    "        # Remember to extract features at the adaptation layer for computing MMD loss\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training the DDC Network\n",
    "\n",
    "Now, let's implement the training procedure for the DDC network, which involves optimizing both classification and domain confusion losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the training function for DDC\n",
    "def train_ddc(model, source_loader, target_loader, num_epochs=20, learning_rate=0.001, \n",
    "              lambda_mmd=0.25, beta1=0.9, beta2=0.999):\n",
    "    \"\"\"\n",
    "    Train the DDC network\n",
    "    \n",
    "    Args:\n",
    "        model (DDCNet): The DDC network\n",
    "        source_loader (DataLoader): DataLoader for source domain\n",
    "        target_loader (DataLoader): DataLoader for target domain\n",
    "        num_epochs (int): Number of training epochs\n",
    "        learning_rate (float): Learning rate\n",
    "        lambda_mmd (float): Weight for the MMD loss\n",
    "        beta1, beta2 (float): Beta parameters for Adam optimizer\n",
    "        \n",
    "    Returns:\n",
    "        model (DDCNet): Trained model\n",
    "        history (dict): Training history (losses and accuracies)\n",
    "    \"\"\"\n",
    "    # TODO: Set up optimizer, loss function, and training loop\n",
    "    # Make sure to optimize both classification and domain confusion losses\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "    \n",
    "    # Initialize loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize history\n",
    "    history = {'loss': [], 'accuracy': []}\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # TODO: Implement training loop\n",
    "        # 1. Forward pass\n",
    "        # 2. Compute classification loss\n",
    "        # 3. Compute domain confusion loss\n",
    "        # 4. Compute total loss\n",
    "        # 5. Backward pass\n",
    "        # 6. Update weights\n",
    "        # 7. Compute accuracy\n",
    "        # 8. Store loss and accuracy\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the testing function for DDC\n",
    "def test_ddc(model, target_loader):\n",
    "    \"\"\"\n",
    "    Test the DDC network on the target domain\n",
    "    \n",
    "    Args:\n",
    "        model (DDCNet): The trained DDC network\n",
    "        target_loader (DataLoader): DataLoader for target domain\n",
    "        \n",
    "    Returns:\n",
    "        accuracy (float): Classification accuracy on the target domain\n",
    "    \"\"\"\n",
    "    # TODO: Implement the testing procedure\n",
    "    # 1. Initialize accuracy counter\n",
    "    # 2. Iterate over target domain data\n",
    "    # 3. Compute predictions and accuracy\n",
    "    # 4. Return accuracy\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Ablation Studies and Experiments\n",
    "\n",
    "Now that we have implemented the DDC network, let's conduct some experiments to understand the contribution of each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement experiments to analyze the contribution of different components\n",
    "def run_experiments():\n",
    "    \"\"\"\n",
    "    Run experiments to analyze different aspects of the DDC network\n",
    "    \n",
    "    Experiments to consider:\n",
    "    1. Effect of adaptation layer position\n",
    "    2. Effect of adaptation layer dimension\n",
    "    3. Effect of lambda_mmd (weight for the MMD loss)\n",
    "    4. Comparison with fine-tuning a pre-trained model without domain adaptation\n",
    "    \"\"\"\n",
    "    # TODO: Implement various experiments\n",
    "    # 1. Effect of adaptation layer position\n",
    "    # 2. Effect of adaptation layer dimension\n",
    "    # 3. Effect of lambda_mmd (weight for the MMD loss)\n",
    "    # 4. Comparison with fine-tuning a pre-trained model without domain adaptation\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Visualizing Domain Adaptation\n",
    "\n",
    "Finally, let's visualize how the features change during the domain adaptation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement feature visualization\n",
    "def visualize_features(model, source_loader, target_loader, epoch=0):\n",
    "    \"\"\"\n",
    "    Visualize features from source and target domains using t-SNE\n",
    "    \n",
    "    Args:\n",
    "        model (DDCNet): The DDC network\n",
    "        source_loader (DataLoader): DataLoader for source domain\n",
    "        target_loader (DataLoader): DataLoader for target domain\n",
    "        epoch (int): Current training epoch\n",
    "    \"\"\"\n",
    "    # TODO: Implement feature visualization with t-SNE\n",
    "    # Extract features from the adaptation layer\n",
    "    # Apply t-SNE for dimensionality reduction\n",
    "    # Plot the source and target features in different colors\n",
    "    tsne = TSNE()\n",
    "    \n",
    "    # Extract features from the adaptation layer\n",
    "    # TODO: Implement feature extraction\n",
    "    source_features = []\n",
    "    target_features = []\n",
    "    \n",
    "    # Apply t-SNE for dimensionality reduction\n",
    "\n",
    "    combined_features = np.vstack((source_features, target_features))\n",
    "    t_sne_features = tsne.fit_transform(combined_features)\n",
    "\n",
    "    # Plot the source and target features in different colors\n",
    "    # TODO: Implement visualization \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(t_sne_features[:len(source_features), 0], t_sne_features[:len(source_features), 1], c='blue', label='Source')\n",
    "    plt.scatter(t_sne_features[len(source_features):, 0], t_sne_features[len(source_features):, 1], c='red', label='Target')\n",
    "    plt.legend()\n",
    "    plt.title(f'Feature Distribution (Epoch {epoch})')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.savefig(f'feature_distribution_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Implementing the Complete Pipeline\n",
    "\n",
    "Now let's put everything together and implement the complete DDC training and evaluation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the main function to run the complete pipeline\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    source_domain = 'amazon'\n",
    "    target_domain = 'webcam'\n",
    "    num_classes = 31\n",
    "    batch_size = 32\n",
    "    num_epochs = 20\n",
    "    learning_rate = 0.001\n",
    "    lambda_mmd = 0.25\n",
    "    adaptation_layer_dim = 256\n",
    "    \n",
    "    # Create data loaders\n",
    "    source_loader, target_loader = get_office31_dataloaders(\n",
    "        source_domain, target_domain, batch_size)\n",
    "    \n",
    "    # Create the DDC network\n",
    "    model = DDCNet(num_classes=num_classes, \n",
    "                  adaptation_layer_dim=adaptation_layer_dim).to(device)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, history = train_ddc(\n",
    "        model, source_loader, target_loader, num_epochs, \n",
    "        learning_rate, lambda_mmd)\n",
    "    \n",
    "    # Test the model\n",
    "    target_accuracy = test_ddc(trained_model, target_loader)\n",
    "    print(f\"Target domain accuracy: {target_accuracy:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_class_loss'], label='Classification Loss')\n",
    "    plt.plot(history['train_mmd_loss'], label='MMD Loss')\n",
    "    plt.plot(history['train_total_loss'], label='Total Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Source Accuracy')\n",
    "    plt.plot(history['target_accuracy'], label='Target Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Run additional experiments\n",
    "    run_experiments()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and Extensions (for Advanced Students)\n",
    "\n",
    "1. **Multi-Domain Adaptation**: Extend the DDC approach to handle multiple source or target domains.\n",
    "2. **Different Network Architectures**: Implement the DDC approach with more modern architectures like ResNet or DenseNet.\n",
    "3. **Alternative Domain Discrepancy Measures**: Replace MMD with other domain discrepancy measures like CORAL (Correlation Alignment) or adversarial training.\n",
    "4. **Partial Domain Adaptation**: Modify the approach to handle the case where the target domain contains only a subset of the source domain classes.\n",
    "5. **Parameter Sensitivity Analysis**: Conduct a thorough analysis of how different hyperparameters affect the performance of the DDC approach.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., & Darrell, T. (2014). Deep Domain Confusion: Maximizing for Domain Invariance. arXiv preprint arXiv:1412.3474.\n",
    "2. Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B., & Smola, A. (2012). A kernel two-sample test. Journal of Machine Learning Research, 13(Mar), 723-773.\n",
    "3. Saenko, K., Kulis, B., Fritz, M., & Darrell, T. (2010). Adapting visual category models to new domains. In European conference on computer vision (pp. 213-226)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
