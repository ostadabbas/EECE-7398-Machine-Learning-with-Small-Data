{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518304bf",
   "metadata": {},
   "source": [
    "# Assignment: CIFAR-10 Classification with Custom Modifications and Experiment Monitoring\n",
    "\n",
    "**Objective**: This assignment will guide you through building, training, and tracking a custom CNN for CIFAR-10 classification. You will use Weights & Biases (W&B) to monitor your experiments, fine-tune your model, and run inference on new images.\n",
    "\n",
    "Complete the tasks below using a Jupyter Notebook. Make sure to track and log your experiments using **Weights & Biases**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Set Up Your Environment\n",
    "\n",
    "1. **Install Required Libraries**:\n",
    "   - Install the following libraries if not already installed:\n",
    "   ```bash\n",
    "   pip install torch torchvision wandb matplotlib\n",
    "   ```\n",
    "\n",
    "2. **Log in to Weights & Biases**:\n",
    "   - Log in to Weights & Biases using your API key. You can obtain it from [https://wandb.ai/](https://wandb.ai/).\n",
    "   ```bash\n",
    "   wandb login YOUR_API_KEY\n",
    "   ```\n",
    "\n",
    "3. **Initialize Weights & Biases**:\n",
    "   - Set up a new project in W&B for tracking your experiments:\n",
    "   ```python\n",
    "   import wandb\n",
    "   wandb.init(project=\"cifar10_custom_classifier\", entity=\"your_entity\")\n",
    "\n",
    "   # Log hyperparameters\n",
    "   ```python\n",
    "   wandb.config = {\n",
    "       \"learning_rate\": 0.001,\n",
    "       \"epochs\": 10,\n",
    "       \"batch_size\": 64,\n",
    "       \"optimizer\": \"Adam\"\n",
    "   }\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Model Creation and Training\n",
    "\n",
    "1. **Define a Custom CNN Model**:\n",
    "   - Create a custom CNN model for CIFAR-10 classification. You can start by modifying the basic model you've learned, and experiment with additional layers (e.g., adding more convolutional layers, batch normalization, or dropout).\n",
    "\n",
    "   **Task**:\n",
    "   - Define your own CNN architecture and explain the reasoning behind your design choices (e.g., why did you add an extra layer?).\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   class CustomCNN(nn.Module):\n",
    "       def __init__(self):\n",
    "           super(CustomCNN, self).__init__()\n",
    "           self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "           self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "           self.conv3 = nn.Conv2d(64, 128, 3, 1)  # New layer\n",
    "           self.fc1 = nn.Linear(128*4*4, 256)\n",
    "           self.fc2 = nn.Linear(256, 10)\n",
    "           \n",
    "       def forward(self, x):\n",
    "           x = F.relu(self.conv1(x))\n",
    "           x = F.relu(self.conv2(x))\n",
    "           x = F.max_pool2d(F.relu(self.conv3(x)), 2)  # New layer activation\n",
    "           x = x.view(-1, 128*4*4)\n",
    "           x = F.relu(self.fc1(x))\n",
    "           x = self.fc2(x)\n",
    "           return F.log_softmax(x, dim=1)\n",
    "   ```\n",
    "\n",
    "2. **Train the Model**:\n",
    "   - Train the model using the **CIFAR-10** dataset and log the following metrics to W&B:\n",
    "     - Training Loss\n",
    "     - Validation Accuracy\n",
    "     - System resource usage (e.g., GPU utilization)\n",
    "\n",
    "   **Task**:\n",
    "   - Train your model for **10 epochs** using the optimizer of your choice (e.g., Adam or SGD). Log all relevant metrics to W&B using `wandb.log()`.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   for epoch in range(1, 11):  # 10 epochs\n",
    "       train(model, device, train_loader, optimizer, epoch)\n",
    "       test(model, device, test_loader)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Hyperparameter Tuning and Experiment Tracking\n",
    "\n",
    "1. **Experiment with Hyperparameters**:\n",
    "   - Try different hyperparameters, such as:\n",
    "     - Learning rate (e.g., `0.001`, `0.0001`)\n",
    "     - Batch size (e.g., `32`, `64`, `128`)\n",
    "     - Optimizer (Adam vs. SGD)\n",
    "\n",
    "   **Task**:\n",
    "   - Run **at least two additional experiments** with different hyperparameters, log the results to W&B, and compare the outcomes (e.g., which combination of hyperparameters led to better performance?).\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   wandb.config.update({\"learning_rate\": 0.0001, \"optimizer\": \"SGD\"})\n",
    "   optimizer = optim.SGD(model.parameters(), lr=wandb.config.learning_rate)\n",
    "   ```\n",
    "\n",
    "2. **Compare Experiment Results**:\n",
    "   - Use the W&B dashboard to compare different runs. Identify the best-performing model based on accuracy and loss metrics.\n",
    "   - Summarize your findings in a Markdown cell: Which hyperparameter configuration worked best? Why do you think it performed better?\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Run Inference on Custom Images\n",
    "\n",
    "1. **Load a Custom Image**:\n",
    "   - Find a custom image online (or use any image you have). Resize it to 32x32, normalize it, and run it through your model for inference.\n",
    "\n",
    "   **Task**:\n",
    "   - Perform inference on at least **two custom images**. Log the results to W&B by recording the predicted label for each image.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   from PIL import Image\n",
    "   import requests\n",
    "   from torchvision import transforms\n",
    "\n",
    "   # Load a custom image from URL\n",
    "   url = \"https://example.com/your_image.jpg\"\n",
    "   img = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "   # Preprocess the image\n",
    "   preprocess = transforms.Compose([\n",
    "       transforms.Resize((32, 32)),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "   ])\n",
    "   img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "   # Run inference\n",
    "   model.eval()\n",
    "   with torch.no_grad():\n",
    "       output = model(img_tensor)\n",
    "       pred = output.argmax(dim=1, keepdim=True)\n",
    "       print(f\"Predicted label: {pred.item()}\")\n",
    "       wandb.log({\"Custom Image Prediction\": pred.item()})\n",
    "   ```\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
