{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Exercise Part 2: Requesting GPU Resources and Running PyTorch\n", "In this part, we will demonstrate how to request GPU resources on the Discovery Cluster using SLURM and run your PyTorch training script or notebook on the GPU."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Loading Required Modules and Setting Up the Environment\n", "Before requesting GPU resources, ensure that the required modules are loaded, and the environment is set up properly.\n", "Run the following commands in the terminal or notebook to load the required modules and create a new Conda environment."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Loading the required modules\n", "%%bash\n", "module load anaconda3/2022.05 cuda/11.7\n", "\n", "# Create a Conda environment in the scratch space for the current user\n", "conda create --prefix=/scratch/$USER/pytorch_env_course python=3.9 -y\n", "\n", "# Activate the environment\n", "source activate /scratch/$USER/pytorch_env_course\n", "\n", "# Install JupyterLab\n", "conda install jupyterlab -y\n", "\n", "# Install PyTorch and related libraries with CUDA 11.7 support\n", "conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia -y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Requesting GPU Resources\n", "Use SLURM to request GPU resources for training. The following commands are used to request GPU nodes during and after training.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["##### Use after training ######\n", "%%bash\n", "srun --partition=gpu --nodes=1 --cpus-per-task=1 --gres=gpu:1 --mem=2G --time=00:05:00 --pty /bin/bash\n", "################################\n", "\n", "##### Use during training ######\n", "srun --partition=reservation --reservation=bootcamp_gpu_2023 --gres=gpu:1 --nodes=1 --cpus-per-task=1 --pty --mem=2G --time=00:05:00 /bin/bash\n", "################################\n", "\n", "# Requesting a GPU node\n", "srun --partition=gpu --nodes=1 --cpus-per-task=1 --gres=gpu:1 --mem=2G --time=00:05:00 --pty /bin/bash\n", "nvidia-smi\n", "exit\n", "\n", "# Requesting a GPU node with a specific type of GPU\n", "srun --partition=gpu --nodes=1 --cpus-per-task=1 --gres=gpu:p100:1 --mem=2G --time=00:05:00 --pty /bin/bash\n", "nvidia-smi\n", "exit\n", "\n", "# Check available features on the GPU partition\n", "sinfo -p gpu --Format=nodes,cpus,nodelist,gres,features\n", "sinfo -p gpu --Format=nodes,cpus,nodelist,gres,statecompact,features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These commands will allow you to request GPU resources for running your PyTorch models on the Discovery Cluster."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}