{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Deep Learning Environment Setup Guide\n",
    "\n",
    "This notebook will guide you through setting up your deep learning environment on your personal computer. You can run each cell to execute the setup commands directly.\n",
    "\n",
    "## Table of Contents\n",
    "1. [System Information](#system-info)\n",
    "2. [Environment Setup](#environment-setup)\n",
    "3. [Package Installation](#package-installation)\n",
    "4. [Environment Verification](#verification)\n",
    "5. [Additional Tools Setup](#additional-tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Information <a name=\"system-info\"></a>\n",
    "\n",
    "Run this cell to get information about your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux\n",
      "OS Version: #1 SMP PREEMPT_DYNAMIC Wed Dec 13 14:07:45 UTC 2023\n",
      "Machine: x86_64\n",
      "Python Version: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "GPU: NVIDIA GPU detected\n",
      "\n",
      "GPU Information:\n",
      "Wed Sep 10 10:06:20 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              28W / 250W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def get_system_info():\n",
    "    system_info = {\n",
    "        'OS': platform.system(),\n",
    "        'OS Version': platform.version(),\n",
    "        'Machine': platform.machine(),\n",
    "        'Python Version': sys.version.split('\\n')[0]\n",
    "    }\n",
    "    \n",
    "    # Check for NVIDIA GPU\n",
    "    try:\n",
    "        nvidia_smi = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
    "        system_info['GPU'] = 'NVIDIA GPU detected'\n",
    "        system_info['GPU Info'] = nvidia_smi\n",
    "    except:\n",
    "        system_info['GPU'] = 'No NVIDIA GPU detected'\n",
    "    \n",
    "    return system_info\n",
    "\n",
    "system_info = get_system_info()\n",
    "for key, value in system_info.items():\n",
    "    if key != 'GPU Info':\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "if 'GPU Info' in system_info:\n",
    "    print(\"\\nGPU Information:\")\n",
    "    print(system_info['GPU Info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup <a name=\"environment-setup\"></a>\n",
    "\n",
    "### 2.1 Check Conda Installation\n",
    "First, let's verify if Conda is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conda is installed: conda 24.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_conda():\n",
    "    try:\n",
    "        conda_version = subprocess.check_output(['conda', '--version']).decode('utf-8')\n",
    "        print(f\"✅ Conda is installed: {conda_version}\")\n",
    "        return True\n",
    "    except:\n",
    "        print(\"❌ Conda is not installed. Please install Miniconda:\")\n",
    "        os_name = platform.system()\n",
    "        if os_name == 'Windows':\n",
    "            print(\"Download Miniconda for Windows: https://docs.conda.io/en/latest/miniconda.html\")\n",
    "        elif os_name == 'Darwin':\n",
    "            print(\"Run in terminal:\\n\"\n",
    "                  \"wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\\n\"\n",
    "                  \"bash Miniconda3-latest-MacOSX-x86_64.sh\")\n",
    "        else:\n",
    "            print(\"Run in terminal:\\n\"\n",
    "                  \"wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\\n\"\n",
    "                  \"bash Miniconda3-latest-Linux-x86_64.sh\")\n",
    "        return False\n",
    "\n",
    "conda_installed = check_conda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create and Activate Environment\n",
    "If Conda is installed, run these cells to create and activate the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 25.1.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.1.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/nail/anaconda3/envs/ml_course_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.8\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.12.31 |       h06a4308_0         128 KB\n",
      "    ld_impl_linux-64-2.40      |       h12ee557_0         710 KB\n",
      "    pip-24.2                   |   py38h06a4308_0         2.2 MB\n",
      "    python-3.8.20              |       he870216_0        23.8 MB\n",
      "    setuptools-75.1.0          |   py38h06a4308_0         1.7 MB\n",
      "    wheel-0.44.0               |   py38h06a4308_0         108 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        28.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.12.31-h06a4308_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.15-h5eee18b_0 \n",
      "  pip                pkgs/main/linux-64::pip-24.2-py38h06a4308_0 \n",
      "  python             pkgs/main/linux-64::python-3.8.20-he870216_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0 \n",
      "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ld_impl_linux-64-2.4 | 710 KB    |            |   0% \n",
      "wheel-0.44.0         | 108 KB    |            |   0% \u001b[A\n",
      "\n",
      "ca-certificates-2024 | 128 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-24.2             | 2.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 710 KB    | 2          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-24.2             | 2.2 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "ca-certificates-2024 | 128 KB    | #2         |  12% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    |            |   1% \u001b[A\u001b[A\u001b[A\n",
      "wheel-0.44.0         | 108 KB    | #4         |  15% \u001b[A\n",
      "\n",
      "ld_impl_linux-64-2.4 | 710 KB    | #5         |  16% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-24.2             | 2.2 MB    | ##1        |  22% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    | ##4        |  25% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-24.2             | 2.2 MB    | ####5      |  46% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    | ######7    |  68% \u001b[A\u001b[A\u001b[A\n",
      "wheel-0.44.0         | 108 KB    | ########8  |  89% \u001b[A\n",
      "wheel-0.44.0         | 108 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.4 | 710 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #3         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | ##2        |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "setuptools-75.1.0    | 1.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-24.2             | 2.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | ##9        |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | ###5       |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | ####9      |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #####7     |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | ######4    |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #######2   |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #######8   |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #########  |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #########5 |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.8.20        | 23.8 MB   | #########9 | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                     \u001b[A\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate ml_course_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda create -n ml_course_env python=3.10 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda activate course_env\n",
    "python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package Installation <a name=\"package-installation\"></a>\n",
    "\n",
    "### 3.1 Install PyTorch\n",
    "Run the appropriate cell based on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For systems with NVIDIA GPU\n",
    "%%bash\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For systems without GPU (CPU only)\n",
    "%%bash\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Install Additional Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda install jupyter matplotlib pandas scikit-learn -y\n",
    "pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Environment Verification <a name=\"verification\"></a>\n",
    "\n",
    "Let's verify that everything is installed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch: 2.5.1+cu121\n",
      "✅ TorchVision: 0.20.1+cu121\n",
      "❌ Matplotlib: Not installed\n",
      "❌ Pandas: Not installed\n",
      "❌ Scikit-learn: Not installed\n",
      "✅ Weights & Biases: unknown version\n",
      "✅ CUDA available: 12.1\n",
      "✅ GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "def verify_installation():\n",
    "    packages_to_check = {\n",
    "        'torch': 'PyTorch',\n",
    "        'torchvision': 'TorchVision',\n",
    "        'matplotlib': 'Matplotlib',\n",
    "        'pandas': 'Pandas',\n",
    "        'sklearn': 'Scikit-learn',\n",
    "        'wandb': 'Weights & Biases'\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for package, name in packages_to_check.items():\n",
    "        try:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'unknown version')\n",
    "            results.append(f\"✅ {name}: {version}\")\n",
    "        except ImportError:\n",
    "            results.append(f\"❌ {name}: Not installed\")\n",
    "    \n",
    "    # Check CUDA availability\n",
    "    import torch\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if cuda_available:\n",
    "        results.append(f\"✅ CUDA available: {torch.version.cuda}\")\n",
    "        results.append(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        results.append(\"ℹ️ Running on CPU only\")\n",
    "    \n",
    "    return '\\n'.join(results)\n",
    "\n",
    "print(verify_installation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Additional Tools Setup <a name=\"additional-tools\"></a>\n",
    "\n",
    "### 5.1 Configure Jupyter Extensions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install jupyter_contrib_nbextensions\n",
    "jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Test GPU Performance (if available)\n",
    "If you have a GPU, run this cell to test its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Performance Test: 0.0199 seconds per operation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "def test_gpu_performance():\n",
    "    if not torch.cuda.is_available():\n",
    "        return \"No GPU available for testing\"\n",
    "    \n",
    "    # Create large tensors\n",
    "    size = 5000\n",
    "    a = torch.randn(size, size, device='cuda')\n",
    "    b = torch.randn(size, size, device='cuda')\n",
    "    \n",
    "    # Warm-up\n",
    "    torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Measure performance\n",
    "    start_time = time.time()\n",
    "    for _ in range(10):\n",
    "        torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return f\"GPU Performance Test: {(end_time - start_time) / 10:.4f} seconds per operation\"\n",
    "\n",
    "print(test_gpu_performance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter any issues, run this diagnostic cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Path: /home/galoaa.b/.conda/envs/ml-env/bin/python\n",
      "\n",
      "Conda Environment: ml-env\n",
      "\n",
      "PyTorch Build: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\n",
      "NVIDIA Driver Info:\n",
      "Wed Sep 10 10:08:35 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              45W / 250W |    630MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1258837      C   ...oaa.b/.conda/envs/ml-env/bin/python      626MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_diagnostics():\n",
    "    diagnostics = []\n",
    "    \n",
    "    # System paths\n",
    "    diagnostics.append(f\"Python Path: {sys.executable}\")\n",
    "    \n",
    "    # Conda environment\n",
    "    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'Not in a conda environment')\n",
    "    diagnostics.append(f\"Conda Environment: {conda_env}\")\n",
    "    \n",
    "    # PyTorch build info\n",
    "    if 'torch' in sys.modules:\n",
    "        import torch\n",
    "        diagnostics.append(f\"PyTorch Build: {torch.__config__.show()}\")\n",
    "    \n",
    "    # GPU drivers\n",
    "    try:\n",
    "        nvidia_smi = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
    "        diagnostics.append(f\"NVIDIA Driver Info:\\n{nvidia_smi}\")\n",
    "    except:\n",
    "        diagnostics.append(\"NVIDIA drivers not found or not accessible\")\n",
    "    \n",
    "    return '\\n\\n'.join(diagnostics)\n",
    "\n",
    "print(run_diagnostics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If all cells ran successfully, your environment is ready for deep learning! You can now:\n",
    "1. Start working on the course notebooks\n",
    "2. Try running some basic PyTorch operations\n",
    "3. Set up your Weights & Biases account for experiment tracking\n",
    "\n",
    "If you encountered any issues, please:\n",
    "1. Run the diagnostic cell above\n",
    "2. Check the error messages\n",
    "3. Consult the course documentation or reach out to the instructors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
