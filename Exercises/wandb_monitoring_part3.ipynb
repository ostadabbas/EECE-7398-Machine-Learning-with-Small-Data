{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f849e4eb",
   "metadata": {},
   "source": [
    "# Weights & Biases (W&B) Monitoring for PyTorch Experiments\n",
    "In this notebook, we will set up and use **Weights & Biases (W&B)** to monitor our PyTorch training experiments on the RC cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c53c80",
   "metadata": {},
   "source": [
    "## What is Weights & Biases (W&B)?\n",
    "W&B is a platform for tracking machine learning experiments. It allows you to visualize and compare training runs, track hyperparameters, log metrics like loss and accuracy, and view system resource usage. All this can be done via a web interface without needing to SSH into the system for every update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6c759",
   "metadata": {},
   "source": [
    "## Step 1: Installing Weights & Biases\n",
    "First, we need to install the `wandb` Python package in our Conda environment. You can install it by running the following command in your terminal or notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command in your terminal to install W&B\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498463e9",
   "metadata": {},
   "source": [
    "## Step 2: Log in to W&B\n",
    "After installing W&B, you'll need to log in to your W&B account. If you don't have an account, you can sign up for free at [https://wandb.ai](https://wandb.ai).\n",
    "Once you have your API key, log in by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to W&B (replace YOUR_API_KEY with your actual W&B API key)\n",
    "!wandb login YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6892c9",
   "metadata": {},
   "source": [
    "## Step 3: Modifying Your PyTorch Training Script for W&B\n",
    "Next, we'll modify our PyTorch training script to log metrics like loss and accuracy to W&B. We'll also log hyperparameters like the learning rate, batch size, and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "# Step 1: Initialize a W&B run\n",
    "wandb.init(project=\"cifar10_classification\", entity=\"student_project\")\n",
    "\n",
    "# Log hyperparameters\n",
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 64,\n",
    "}\n",
    "\n",
    "# Step 2: Define the CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(64*6*6, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 64*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Step 3: Load and preprocess CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Step 4: Training and Testing Functions\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Log loss to W&B\n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    wandb.log({\"accuracy\": accuracy})\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Step 5: Set device, initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "# Step 6: Train the model for 5 epochs and log metrics\n",
    "for epoch in range(1, wandb.config.epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b809c1",
   "metadata": {},
   "source": [
    "## Step 4: Viewing Results on W&B Dashboard\n",
    "Once your training starts, you can view live metrics on your W&B dashboard at [https://wandb.ai](https://wandb.ai).\n",
    "You can see metrics like training loss, accuracy, and other parameters in real-time without needing to SSH into the cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
