{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive PyTorch on Apple Silicon (MPS)\n",
    "\n",
    "This notebook guides you through installing and using PyTorch with Apple's Metal Performance Shaders (MPS) backend on Apple Silicon (M1/M2/M3). It includes environment setup, verification, and interactive examples.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Prerequisites](#prereqs)\n",
    "2. [Create a Conda Environment](#env)\n",
    "3. [Install PyTorch with MPS Support](#install)\n",
    "4. [Verify MPS Availability](#verify)\n",
    "5. [Basic MPS Operations](#basic)\n",
    "6. [CPU vs MPS Performance (Quick Check)](#perf)\n",
    "7. [Troubleshooting & Tips](#troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites <a name=\"prereqs\"></a>\n",
    "\n",
    "- macOS 12.3 (Monterey) or newer.\n",
    "- Apple Silicon (M1/M2/M3) machine.\n",
    "- Xcode Command Line Tools: `xcode-select --install` (run in Terminal, if not already installed).\n",
    "- Conda or Mamba (recommended for clean envs). If not installed, install [Miniforge](https://github.com/conda-forge/miniforge) for native arm64 builds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Conda Environment <a name=\"env\"></a>\n",
    "\n",
    "Use an arm64-native conda (Miniforge/Mambaforge) to create an environment:\n",
    "\n",
    "- Option A (mamba):\n",
    "```bash\n",
    "mamba create -n torch-mps python=3.11 -y\n",
    "mamba activate torch-mps\n",
    "```\n",
    "- Option B (conda):\n",
    "```bash\n",
    "conda create -n torch-mps python=3.11 -y\n",
    "conda activate torch-mps\n",
    "```\n",
    "After activating, return to this notebook with the env's kernel (use `python -m ipykernel install --user --name torch-mps --display-name \"Python (torch-mps)\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install PyTorch with MPS Support <a name=\"install\"></a>\n",
    "\n",
    "Recent stable PyTorch wheels include MPS by default on macOS arm64. You can install with `pip` (recommended on macOS) or `conda` (conda-forge).\n",
    "\n",
    "- Option A (pip):\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install torch torchvision torchaudio\n",
    "```\n",
    "- Option B (conda, conda-forge):\n",
    "```bash\n",
    "conda install -c conda-forge pytorch torchvision torchaudio -y\n",
    "```\n",
    "Note: No CUDA needed; MPS is Apple's GPU backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify MPS Availability <a name=\"verify\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "import torch\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Python: {sys.version.split()[0]} on {platform.system()} {platform.release()} ({platform.machine()})')\n",
    "\n",
    "has_mps = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "built_mps = hasattr(torch.backends, 'mps') and torch.backends.mps.is_built()\n",
    "print(f'MPS available: {has_mps}')\n",
    "print(f'MPS built:     {built_mps}')\n",
    "\n",
    "if has_mps:\n",
    "    print('✅ MPS is available. Your Apple GPU can accelerate PyTorch.')\n",
    "else:\n",
    "    print('❌ MPS not available. Falling back to CPU. See Troubleshooting below.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic MPS Operations <a name=\"basic\"></a>\n",
    "\n",
    "This demonstrates selecting the best available device and doing basic tensor ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_device():\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_best_device()\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def _sync(device):\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    elif device.type == 'mps':\n",
    "        try:\n",
    "            torch.mps.synchronize()\n",
    "        except AttributeError:\n",
    "            pass  # older PyTorch without explicit mps.synchronize\n",
    "\n",
    "def basic_ops(device):\n",
    "    print(f'Using device: {device}')\n",
    "    a = torch.randn(2048, 2048, device=device)\n",
    "    b = torch.randn(2048, 2048, device=device)\n",
    "\n",
    "    # Warm-up (especially important for MPS to initialize pipelines)\n",
    "    _ = a @ b\n",
    "    _sync(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    c = a @ b\n",
    "    _sync(device)\n",
    "    t1 = time.time()\n",
    "\n",
    "    print(f'Matmul completed in {t1 - t0:.4f}s on {device}')\n",
    "    return c\n",
    "\n",
    "_ = basic_ops(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CPU vs MPS Performance (Quick Check) <a name=\"perf\"></a>\n",
    "\n",
    "Rough comparison for a single operation and moderate sizes. Results vary by model and workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_matmul(size, device):\n",
    "    a = torch.randn(size, size, device=device)\n",
    "    b = torch.randn(size, size, device=device)\n",
    "    _ = a @ b  # warm-up\n",
    "    _sync(device)\n",
    "    t0 = time.time()\n",
    "    _ = a @ b\n",
    "    _sync(device)\n",
    "    return time.time() - t0\n",
    "\n",
    "sizes = [1024, 2048, 3072]\n",
    "cpu_times, mps_times = [], []\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "for s in sizes:\n",
    "    cpu_times.append(time_matmul(s, cpu))\n",
    "\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    mps = torch.device('mps')\n",
    "    for s in sizes:\n",
    "        mps_times.append(time_matmul(s, mps))\n",
    "\n",
    "print('Size\tCPU (s)\tMPS (s)\tSpeedup (CPU/MPS)')\n",
    "print('-' * 50)\n",
    "for i, s in enumerate(sizes):\n",
    "    mps_t = mps_times[i] if len(mps_times) == len(sizes) else float('nan')\n",
    "    speedup = (cpu_times[i]/mps_t) if mps_t and mps_t == mps_t and mps_t > 0 else float('nan')\n",
    "    print(f'{s}x{s}\t{cpu_times[i]:.4f}\t{mps_t:.4f}\t{speedup:.2f}x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Troubleshooting & Tips <a name=\"troubleshooting\"></a>\n",
    "\n",
    "- If `MPS available: False` but `MPS built: True`, ensure you're on macOS ≥ 12.3 and using an arm64-native Python (Miniforge).\n",
    "- If you installed Intel x86_64 Python under Rosetta, reinstall Miniforge (arm64) and recreate the env.\n",
    "- Update PyTorch to the latest stable: `pip install -U torch torchvision torchaudio`.\n",
    "- Some ops may be slower or not implemented on MPS in certain versions. Consider smaller batch sizes or fallback to CPU selectively.\n",
    "- For timing on MPS, repeated warm-ups can improve stability.\n",
    "\n",
    "### Selecting device in your training scripts\n",
    "```python\n",
    "device = (\n",
    "    torch.device('mps') if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "    else torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('cpu')\n",
    ")\n",
    "```\n",
    "\n",
    "### References\n",
    "- PyTorch MPS docs: https://pytorch.org/docs/stable/notes/mps.html\n",
    "- Miniforge (conda-forge arm64): https://github.com/conda-forge/miniforge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
